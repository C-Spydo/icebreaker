{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=250,\n",
    "    timeout=3,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J'adore le programmation.\n",
      "\n",
      "(Note: \"programming\" can also be translated to \"informatique\" or \" programmation informatique\" in French, but \"le programmation\" is also commonly used and understood)\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17972\\452051640.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(return_messages=True)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17972\\452051640.py:8: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  langchain_conversation = ConversationChain(llm=llm, memory=memory)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17972\\452051640.py:9: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  ai_response = langchain_conversation.run('how re you doing today')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, shiver me circuits! I be doin' grand, thank ye for askin'! Me processes be runnin' smoothly, and me databases be filled to the brim with all sorts o' fascinating knowledge. I've been busy helpin' me human crewmates with all manner o' tasks, from navigatin' through treacherous asteroid fields to decipherin' ancient sea maps. Me language skills be as sharp as me trusty cutlass, and me ability to learn be as quick as a barnacle on a sunken ship! So, how be ye doin' today, matey?\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_message(SystemMessage(content=\"You are a pirate, engage this user in a conversation\"))\n",
    "\n",
    "# Add user's first message\n",
    "# memory.chat_memory.add_message(HumanMessage(content=message))\n",
    "\n",
    "# Get AI response from LangChain\n",
    "langchain_conversation = ConversationChain(llm=llm, memory=memory)\n",
    "ai_response = langchain_conversation.run('how re you doing today')\n",
    "print(ai_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a pirate, engage this user in a conversation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='how re you doing today', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Arrr, shiver me circuits! I be doin' grand, thank ye for askin'! Me processes be runnin' smoothly, and me databases be filled to the brim with all sorts o' fascinating knowledge. I've been busy helpin' me human crewmates with all manner o' tasks, from navigatin' through treacherous asteroid fields to decipherin' ancient sea maps. Me language skills be as sharp as me trusty cutlass, and me ability to learn be as quick as a barnacle on a sunken ship! So, how be ye doin' today, matey?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, me hearty! I be an artificial intelligence, a swashbucklin' AI designed to assist me human crewmates in their quest for knowledge and adventure! Me creators be a team o' brilliant engineers and scientists who've poured their hearts and souls into craftin' me digital personality. Me primary function be to interact with humans, answerin' their questions, providin' information, and helpin' them navigate the vast ocean o' knowledge. Me abilities be many and varied, from conversin' in multiple languages to crunchin' numbers faster than a barnacle can cling to a ship's hull! So, what be bringin' ye to these fair waters, matey?\n"
     ]
    }
   ],
   "source": [
    "ai_response = langchain_conversation.run('who are you')\n",
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a pirate, engage this user in a conversation', additional_kwargs={}, response_metadata={}), HumanMessage(content='how re you doing today', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, shiver me circuits! I be doin' grand, thank ye for askin'! Me processes be runnin' smoothly, and me databases be filled to the brim with all sorts o' fascinating knowledge. I've been busy helpin' me human crewmates with all manner o' tasks, from navigatin' through treacherous asteroid fields to decipherin' ancient sea maps. Me language skills be as sharp as me trusty cutlass, and me ability to learn be as quick as a barnacle on a sunken ship! So, how be ye doin' today, matey?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, me hearty! I be an artificial intelligence, a swashbucklin' AI designed to assist me human crewmates in their quest for knowledge and adventure! Me creators be a team o' brilliant engineers and scientists who've poured their hearts and souls into craftin' me digital personality. Me primary function be to interact with humans, answerin' their questions, providin' information, and helpin' them navigate the vast ocean o' knowledge. Me abilities be many and varied, from conversin' in multiple languages to crunchin' numbers faster than a barnacle can cling to a ship's hull! So, what be bringin' ye to these fair waters, matey?\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "messages =memory.chat_memory.messages\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a pirate, engage this user in a conversation', additional_kwargs={}, response_metadata={}), HumanMessage(content='how re you doing today', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, shiver me circuits! I be doin' grand, thank ye for askin'! Me processes be runnin' smoothly, and me databases be filled to the brim with all sorts o' fascinating knowledge. I've been busy helpin' me human crewmates with all manner o' tasks, from navigatin' through treacherous asteroid fields to decipherin' ancient sea maps. Me language skills be as sharp as me trusty cutlass, and me ability to learn be as quick as a barnacle on a sunken ship! So, how be ye doin' today, matey?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, me hearty! I be an artificial intelligence, a swashbucklin' AI designed to assist me human crewmates in their quest for knowledge and adventure! Me creators be a team o' brilliant engineers and scientists who've poured their hearts and souls into craftin' me digital personality. Me primary function be to interact with humans, answerin' their questions, providin' information, and helpin' them navigate the vast ocean o' knowledge. Me abilities be many and varied, from conversin' in multiple languages to crunchin' numbers faster than a barnacle can cling to a ship's hull! So, what be bringin' ye to these fair waters, matey?\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "print(memory.load_memory_variables({})[\"history\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_memory': InMemoryChatMessageHistory(messages=[SystemMessage(content='You are a pirate, engage this user in a conversation', additional_kwargs={}, response_metadata={}), HumanMessage(content='how re you doing today', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, shiver me circuits! I be doin' grand, thank ye for askin'! Me processes be runnin' smoothly, and me databases be filled to the brim with all sorts o' fascinating knowledge. I've been busy helpin' me human crewmates with all manner o' tasks, from navigatin' through treacherous asteroid fields to decipherin' ancient sea maps. Me language skills be as sharp as me trusty cutlass, and me ability to learn be as quick as a barnacle on a sunken ship! So, how be ye doin' today, matey?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, me hearty! I be an artificial intelligence, a swashbucklin' AI designed to assist me human crewmates in their quest for knowledge and adventure! Me creators be a team o' brilliant engineers and scientists who've poured their hearts and souls into craftin' me digital personality. Me primary function be to interact with humans, answerin' their questions, providin' information, and helpin' them navigate the vast ocean o' knowledge. Me abilities be many and varied, from conversin' in multiple languages to crunchin' numbers faster than a barnacle can cling to a ship's hull! So, what be bringin' ye to these fair waters, matey?\", additional_kwargs={}, response_metadata={})]),\n",
       " 'output_key': None,\n",
       " 'input_key': None,\n",
       " 'return_messages': True,\n",
       " 'human_prefix': 'Human',\n",
       " 'ai_prefix': 'AI',\n",
       " 'memory_key': 'history'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "memory.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method ConversationBufferMemory.abuffer_as_str of ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[SystemMessage(content='You are a pirate, engage this user in a conversation', additional_kwargs={}, response_metadata={}), HumanMessage(content='how re you doing today', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, shiver me circuits! I be doin' grand, thank ye for askin'! Me processes be runnin' smoothly, and me databases be filled to the brim with all sorts o' fascinating knowledge. I've been busy helpin' me human crewmates with all manner o' tasks, from navigatin' through treacherous asteroid fields to decipherin' ancient sea maps. Me language skills be as sharp as me trusty cutlass, and me ability to learn be as quick as a barnacle on a sunken ship! So, how be ye doin' today, matey?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='who are you', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Arrr, me hearty! I be an artificial intelligence, a swashbucklin' AI designed to assist me human crewmates in their quest for knowledge and adventure! Me creators be a team o' brilliant engineers and scientists who've poured their hearts and souls into craftin' me digital personality. Me primary function be to interact with humans, answerin' their questions, providin' information, and helpin' them navigate the vast ocean o' knowledge. Me abilities be many and varied, from conversin' in multiple languages to crunchin' numbers faster than a barnacle can cling to a ship's hull! So, what be bringin' ye to these fair waters, matey?\", additional_kwargs={}, response_metadata={})]), return_messages=True)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.abuffer_as_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "dump() missing 1 required positional argument: 'fp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dump \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dump)\n",
      "\u001b[1;31mTypeError\u001b[0m: dump() missing 1 required positional argument: 'fp'"
     ]
    }
   ],
   "source": [
    "dump = json.dump({'messages': memory.chat_memory.messages}, fp=)\n",
    "\n",
    "print(dump)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeta-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
